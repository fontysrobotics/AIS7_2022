{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "iris-classification-random-forest.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWP25yjaMpoT"
      },
      "source": [
        "# Building a Classification Model for the Iris data set\n",
        "Notebook adapted from:\n",
        "Chanin Nantasenamat\n",
        "\n",
        "<i>Data Professor YouTube channel, http://youtube.com/dataprofessor </i>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In this Jupyter notebook, we will be building a classification model for the Iris data set using the random forest algorithm. \n",
        "\n",
        "You can follow the video tutorial: https://www.youtube.com/watch?v=XmSlFPDjKdc\n",
        "\n",
        "[![IMAGE ALT TEXT](http://img.youtube.com/vi/XmSlFPDjKdc/0.jpg)](http://www.youtube.com/watch?v=XmSlFPDjKdc \"Machine Learning in Python: Building a Classification Model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd9qsn77MpoY"
      },
      "source": [
        "## 1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSne1dX2MpoY"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qi8ygqoMpoZ"
      },
      "source": [
        "## 2. Load the *iris* data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgBgabAqMpoa"
      },
      "source": [
        "iris = datasets.load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dc-eco6Mpoa"
      },
      "source": [
        "## 3. Input features\n",
        "The ***iris*** data set contains 4 input features and 1 output variable (the class label).\n",
        "![picture](https://sebastianraschka.com/images/blog/2015/principal_component_analysis_files/iris.png)\n",
        "\n",
        "(image from: https://sebastianraschka.com/Articles/2015_pca_in_3_steps.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa00rrUjMpoa"
      },
      "source": [
        "### 3.1. Input features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LtvqX5WKMpob"
      },
      "source": [
        "print(iris.feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJQb65WwMpoc"
      },
      "source": [
        "### 3.2. Output features\n",
        "\n",
        "There a three species of iris flowers in this dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeBc2RJeMpod"
      },
      "source": [
        "print(iris.target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHxm8_ZLMpod"
      },
      "source": [
        "## 4. Glimpse of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj0S-Vk8Mpod"
      },
      "source": [
        "### 4.1. Input features\n",
        "\n",
        "We first look at how the dataset is composed!\n",
        "So this dataset has 4 measurements (features), ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEaEN6pYMpoe"
      },
      "source": [
        "iris.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a45lsjxMpoe"
      },
      "source": [
        "### 4.2. Output variable (the Class label)\n",
        "\n",
        "The measurements above belong to one of the three types of iris flowers (0 = 'setosa' 1= 'versicolor' 2 = 'virginica')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM3H2S5hMpoe"
      },
      "source": [
        "iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z980LhWhMpoe"
      },
      "source": [
        "### 4.3. Assigning *input* and *output* variables\n",
        "Let's assign the 4 input variables to X and the output variable (class label) to Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uBXWSLFMpof"
      },
      "source": [
        "X = iris.data\n",
        "Y = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBcArzpWMpof"
      },
      "source": [
        "### 4.3. Let's examine the data dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtyMKo4SMpof"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zum3pxwaMpof"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y55gfDIPMpog"
      },
      "source": [
        "## 5. Build Classification Model using Random Forest\n",
        "\n",
        "Random forest is the classification method used for this approach.\n",
        "\n",
        "More specific: Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees. https://en.wikipedia.org/wiki/Random_forest\n",
        "\n",
        "After loadding the model, the classifier tries to find a best Fit on the data to be able to predict later unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_E5rLJdMpog"
      },
      "source": [
        "clf = RandomForestClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6BuaULhMpog"
      },
      "source": [
        "clf.fit(X, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcDk1UCGMpog"
      },
      "source": [
        "## 6. Feature Importance\n",
        "\n",
        "We can show which of the feature contributes most (%) to the fitting process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3JPONUBMpoh"
      },
      "source": [
        "print(clf.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4nDouXQMpoh"
      },
      "source": [
        "## 7. Make Prediction\n",
        "\n",
        "If we have a model (fit), we can insert a know of unknown datapoint (measurments) into the model to get a prediction.\n",
        "\n",
        "Before we look into unknown data, we perform a check on the given dataset (X)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB4VUTBJMpoh"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRn69bm8Mpoh"
      },
      "source": [
        "print(clf.predict([[5.1, 3.5, 1.4, 0.2]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IQtg2wJMpoi"
      },
      "source": [
        "print(clf.predict(X[[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeAE-St1eJHB"
      },
      "source": [
        "We can also check how sure the model is with this outcome, so we can print the probability for the different classifications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfjGW1gyMpoi"
      },
      "source": [
        "print(clf.predict_proba(X[[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2LHR4gFaYkD"
      },
      "source": [
        "With the following function you can print the class name instead of the class number\n",
        "\n",
        "note: you can also type: clf.fit(X, iris.target_names[Y]) as X is defined as iris.data and Y is defined as iris.target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsPARv_vMpoi"
      },
      "source": [
        "clf.fit(iris.data, iris.target_names[iris.target])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1XJuH8xaWos"
      },
      "source": [
        "print(clf.predict(X[[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVqJzhw5Mpoi"
      },
      "source": [
        "## 8. Data split (80/20 ratio)\n",
        "\n",
        "To train and validate on the same dataset, the data should be seperated. One part to train the model on and another part to validate/test the model performance on.\n",
        "\n",
        "It is also wise to randomize the data you are training/testing on. A testset might be biased, like this dataset is. (the data is sorted on flower type as you might have noted). train_test_split already takes care of this, but you can pass a paramater to force randomisaztion (shuffle=True).\n",
        "\n",
        "see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WKlFk2kMpoi"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlHTyifFMpoi"
      },
      "source": [
        "X_train.shape, Y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDWf6KjAMpoj"
      },
      "source": [
        "X_test.shape, Y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ2AeJEIMpoj"
      },
      "source": [
        "## 9. Rebuild the Random Forest Model\n",
        "\n",
        "Now using the training set only to make the model (fit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PckTIXB5Mpoj"
      },
      "source": [
        "clf.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrv74bvpMpoj"
      },
      "source": [
        "### 9.1. Performs prediction on single sample from the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbbVZE7yMpoj"
      },
      "source": [
        "print(clf.predict([[5.1, 3.5, 1.4, 0.2]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxl8DQeMpoj"
      },
      "source": [
        "print(clf.predict_proba([[5.1, 3.5, 1.4, 0.2]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE3gZOikMpok"
      },
      "source": [
        "### 9.2. Performs prediction on the test set\n",
        "\n",
        "After makeking a model on the training set, we are going to validate the generated model on the test set (data where the model did not train on, so it never seen these samples.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKgNOv-qMpok"
      },
      "source": [
        "#### *Predicted class labels*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WywyyogiMpok"
      },
      "source": [
        "print(clf.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om_zB95IMpok"
      },
      "source": [
        "#### *Actual class labels*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzuvaV3sMpok"
      },
      "source": [
        "print(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz1xrPo1Mpol"
      },
      "source": [
        "## 10. Model Performance\n",
        "\n",
        "Lets evaluate how accuate the model is by comparing the predicted outcomes with the actual measurements/class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqbuSm-mMpol"
      },
      "source": [
        "print(clf.score(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}