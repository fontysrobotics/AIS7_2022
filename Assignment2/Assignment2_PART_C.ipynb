{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ipnWvssmbh7"
   },
   "source": [
    "# Transfer Learning on your Own Dataset\n",
    "\n",
    "You will get to use the power of Transfer learning with **your own dataset**. So in this assignment you are going to retrain the pre-trained VGG16 Model with your own detectable objects. \n",
    "\n",
    "![](https://miro.medium.com/max/1000/0*xNjEPIZmPvKeqss6)\n",
    "\n",
    "For doing so, you should :\n",
    "\n",
    "* Generate a custom dataset, so take your own images from custom objects (or from the team members).  \n",
    "\n",
    "* Be sure that you take the images from different angles and different distances, different lighting conditions and different backgrounds for each object. In other words, changing the environment where your objects are while training will lead to a better performance (generalization).\n",
    "\n",
    "* Use at least 3 diffent opbjects (3 classes) and at most 10 classes where such dataset should have at least 50-100 images per class. (more images should lead to better detection performance) \n",
    "\n",
    "* Follow the workflow as [decribed before](https://keras.io/guides/transfer_learning/)\n",
    "\n",
    "* Show the output of the different (training) steps and the resulting classification on unseen data and answer the related questions in the subsections below\n",
    "\n",
    "---\n",
    "\n",
    "### Use the following websites that take you trought all the steps of development.\n",
    "\n",
    "The first page explains how to use the VGG-16 model with Keras to classify pre-tained images. \n",
    "> https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This second page explains the complete proces for classification of images using Keras, they start a problem desciption, data praparation, building a custom CNN model and then optimizing this model. After this they look at the same problem solving it with transfer learning. \n",
    "\n",
    "> https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/\n",
    "\n",
    "\n",
    "You can start at the **\"Explore Transfer Learning\"** chapter, although you probably need to look back at earlier parts of this page.  \n",
    "\n",
    "| NOTE: Finetuning by retraining all weights in the network as described in the workflow is Optional |\n",
    "| --- |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT YOUR NAMES \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOH78U5DpU5k"
   },
   "source": [
    "# Initialization\n",
    "\n",
    "load all needed libraries and functions, \n",
    "check the previous tutorial how to correctly load keras and other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Of4Qf_7DpXOS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWrbNzmtuhKG"
   },
   "source": [
    "# Load dataset & Plot a subset\n",
    "\n",
    "load your dataset and show a plot of the subset of your data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTZNxjTkul9u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-P5qhvGumPu"
   },
   "source": [
    "# Prepare Data\n",
    "\n",
    "pre-process your raw input data... rescale... normalize...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1u8MMVYupNb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yal9uYElv_nU"
   },
   "source": [
    "## Define your Model\n",
    "\n",
    "With Transfer learning you take a given network model withouth the last layers, you can take the suggested VGG-16 model as decribed on the given website and add the additional layers. \n",
    "\n",
    "**NOTE:**\n",
    "That the Ouput layer should match your input dataset!\n",
    "\n",
    "\n",
    "\n",
    "* How is your model constructed, how many trainable parameters does it have, and where are they located?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZTFT_GJv_3N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5t5_38HupW3"
   },
   "source": [
    "# Fit the Model\n",
    "\n",
    "Fitting the model is the time consuming part, this depend on the complexity of the model and the amount of training data. With Transfer learning a lot of pre-trained parameters are now 'frozen', this will limit training time (or enables us to train more complex networks with the same processing performance, and so achieving better results)\n",
    "\n",
    "* Which batch size and how many epochs give a good result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rycO-mp9uscG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdzrdzNeusno"
   },
   "source": [
    "# Evaluate Model\n",
    "\n",
    "Show the model accuracy after the training process ... \n",
    "* How accurate is your final model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Vk7p7YnuvR_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRjQRnYluvaH"
   },
   "source": [
    "# learning curves\n",
    "\n",
    "Show the learning curves of your training sequence, of accuracy, value_accuracy and loss, value_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhWeZxmauyCe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8a1ovA8uyMX"
   },
   "source": [
    "# Save model\n",
    "\n",
    "Save the model for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quPWuPwtu3s4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbK5-OQ4u32A"
   },
   "source": [
    "# Evaluate Final Model\n",
    "\n",
    "After training and saving the model you can deploy this model on any given input image. You can start a new application in where you import this model and apply it on any given imput images, so you can just load the model and don't need the timeconsuming training anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zy3j_jLn4I6u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqEeHGjG3fsd"
   },
   "source": [
    "# Make Prediction\n",
    "\n",
    "We can use our saved model to make a prediction on new images that are not trained on... make sure the input images receive the same pre-processing as the images you trained on.\n",
    "\n",
    "So fetch some images from the internet (similar classes, but not from your dataset), prepare them to fit your network and classify them. Do this for  **10 images per class** and show the results!\n",
    "\n",
    "* How good is the detection on you real dataset? (show some statistics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNpwYE5Ru8gn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Questions\n",
    "* Explain what your input object represents and how the result should be classified\n",
    "* Explain the pre-processing steps of the object training image(s) before you can feed it to the network.\n",
    "* What features do you think are extracted (relevant)?\n",
    "* Show (in report and video) how accurate your predicted model is, how does your detection behave in other unseen situations? Also explain in what situation and why it does (not) perform well. Supported your statements by measurement data!\n",
    "* Explain the parameters that you used for re-training this network?\n",
    "* This example uses a custom (but pre-trained) network architecture, explain how it works and why it is build up this way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning\n",
    "Finetuning by retraining all weights in the network as described in the workflow is Optional, but this will lead to a better accuracy of your final model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
